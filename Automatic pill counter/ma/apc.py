# -*- coding: utf-8 -*-
"""python code.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1cud6j9iABm1XJTc3C9VGYFhsRseWASl2
"""

from google.colab import drive
drive.mount('/content/drive')

! pip install --upgrade scipy
! pip install --upgrade scikit-image
! pip install --upgrade imutils
!pip install --upgrade opencv-python
!pip install --upgrade opencv-contrib-python

##########################################################code for pills###########################################
from skimage.feature import peak_local_max
from skimage.morphology import watershed
from scipy import ndimage
import numpy as np
import imutils
import cv2
from google.colab.patches import cv2_imshow
from cv2 import dnn_superres
from collections import Counter

#super resolution(in case the image is small then this function will enlarge it without looking the quality)
def superresolution(img):
  # Create an SR object
  sr = dnn_superres.DnnSuperResImpl_create()
  # Read the desired model
  path = "/content/drive/My Drive/Images/EDSR_x4.pb"
  sr.readModel(path)
  # Set the desired model and scale to get correct pre- and post-processing
  sr.setModel("edsr", 3)
  # Upscale the image
  img = sr.upsample(img)
  return img

##Image processing using threshold
# load the image and perform pyramid mean shift filtering
# to aid the thresholding step
image = cv2.imread("/content/drive/My Drive/Images/final.jpg")
shifted = cv2.pyrMeanShiftFiltering(image, 21, 51)
# convert the mean shift image to grayscale, then apply
# Otsu's thresholding
gray = cv2.cvtColor(shifted, cv2.COLOR_BGR2GRAY)
thresh = cv2.threshold(gray, 0, 255,
    cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]
#cv2.imshow("Thresh", thresh)

# find contours in the thresholded image
cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL,
    cv2.CHAIN_APPROX_SIMPLE)
cnts = imutils.grab_contours(cnts)
print("[INFO] {} unique contours found".format(len(cnts)))
# loop over the contours
for (i, c) in enumerate(cnts):
    # draw the contour
    ((x, y), _) = cv2.minEnclosingCircle(c)
    cv2.putText(image, "#{}".format(i + 1), (int(x) - 10, int(y)),
        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)
    cv2.drawContours(image, [c], -1, (0, 255, 0), 2)
# show the output image
cv2_imshow( image)
cv2.waitKey(0)

###Image processing using watershed algorithm
# load the image and perform pyramid mean shift filtering
# to aid the thresholding step
image = cv2.imread("/content/drive/My Drive/Images/final.jpg")
if (image.shape[0] < 200 or image.shape[1] <200):
  image = superresolution(image)
shifted = cv2.pyrMeanShiftFiltering(image, 21, 51)
cv2_imshow(shifted)
print(image.shape)

############differentiating between light background images and dark back ground images########################
#giving min shape of image as c to k and l so that they will b of same length
c = min(shifted.shape[0],shifted.shape[1])
k =shifted[0,0:c]
l = shifted[0:c,0]
#defining function to check most occured rgb value in the border of the image so that v can know whether to aply threshold or threshold inv
def mostCommon(lst):
  return [Counter(col).most_common(1)[0][0] for col in zip(*lst)]

#adding k and l so that pixels in both borders will be checked if they r light or dark color
lst = k+l
pixel = mostCommon(lst)
print(pixel)

if ((pixel[0] >128) & (pixel[1] > 128) & (pixel[2] > 128)):
  gray = cv2.cvtColor(shifted, cv2.COLOR_BGR2GRAY)
  thresh = cv2.threshold(gray, 0, 255,cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]
else:
  gray = cv2.cvtColor(shifted, cv2.COLOR_BGR2GRAY)
  thresh = cv2.threshold(gray, 0, 255,cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]
cv2_imshow(thresh)

# compute the exact Euclidean distance from every binary
# pixel to the nearest zero pixel, then find peaks in this
# distance map
D = ndimage.distance_transform_edt(thresh)
localMax = peak_local_max(D, indices=False, min_distance=20,labels=thresh)
# perform a connected component analysis on the local peaks,
# using 8-connectivity, then apply the Watershed algorithm
markers = ndimage.label(localMax, structure=np.ones((3, 3)))[0]
labels = watershed(-D, markers, mask=thresh,watershed_line = True)
print("[INFO] {} unique segments found".format(len(np.unique(labels)) - 1))

# loop over the unique labels returned by the Watershed
# algorithm
for label in np.unique(labels):
    # if the label is zero, we are examining the 'background'
    # so simply ignore it
    if label == 0:
        continue
    # otherwise, allocate memory for the label region and draw
    # it on the mask
    mask = np.zeros(gray.shape, dtype="uint8")
    mask[labels == label] = 255
    # detect contours in the mask and grab the largest one
    cnts = cv2.findContours(mask.copy(), cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)
    cnts = imutils.grab_contours(cnts)
    c = max(cnts, key=cv2.contourArea)
    # draw a circle enclosing the object
    ((x, y), r) = cv2.minEnclosingCircle(c)
    cv2.circle(image, (int(x), int(y)), int(r), (0, 255, 0), 2)
    cv2.putText(image, "#{}".format(label), (int(x) - 10, int(y)),
    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)
# show the output image

cv2_imshow(image)
cv2.waitKey(0)
